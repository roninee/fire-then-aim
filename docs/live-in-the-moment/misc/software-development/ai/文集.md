# 言论

> 突然之间就没有现实了，虚拟的世界如此逼真，这真的很令人担忧。我不知道我们该如何看待这个世界，谁知道它是真是假。
>
> -- [加州大学教授 Hany Farid](https://www.npr.org/2023/05/08/1174132413/people-are-trying-to-claim-real-videos-are-deepfakes-the-courts-are-not-amused)，谈 AI 使得深度伪造变得多么容易
>
> 归根结底，博客、播客、短视频都是一个人表达自己的地方，是他们用数字形式说"这就是我"的方式。
>
> -- [《人工智能会扼杀博客吗？》](https://herman.bearblog.dev/will-ai-kill-blogging/)

老牌的 IT 资讯网站 Gizmodo 宣布，它的西班牙语版本全部改为 AI 翻译，编辑都被解雇。

![img](images/bg2023090101.webp)

它的西班牙语网页底部，现在有一行免责声明："本站内容为自动翻译，可能会存在与原意的细微差异。"

Gizmodo 此前还尝试，使用 AI 撰写新闻：只要输入一些基本事实，AI 就会自动生成一篇几百字的报道。这样的做法以后很可能会流行，翻译和编辑将最早被 AI 替代。

# ChatGPT商业应用——LLM是星辰大海.md

#### ChatGPT+教育

  ChatGPT已经对教育行业产生了巨大的影响，据调查*89%的美国学生*使用ChatGPT做作业，甚至有因学生的作业太完美而被老师质疑抄袭，是的，ChatGPT就像一个“哆啦A梦”，仿佛无所不能无所不知，可以告诉我们任何事情。

  最近，著名非盈利教育机构*可汗学院*发布了他们的智能辅导产品：*Khanmigo*，它就是通过GPT进一步打造的，专门训练了教育辅导方面的各种知识，使得它能够在学生遇到问题的时候，只需要点一下*Tutor me*就能够帮助学生解决复杂的问题，而且并*不*像百度一样*直接告诉你答案*，通过循循善诱启发你思考，让你一步步解决问题。Khanmigo还会为你提供量身定制的学习计划，给出学习建议等等。你还能在它设定的场景里进行学习，比如说*批改一篇作文、与机器人进行一场辩论、进行创意写作等等。*

说完大的应用，我们也可以看看在比较小方面下的细分赛道的应用，比如说**“口语教育**”，也许你还不知道，**ChatGPT是可以说话的**，靠什么呢？很简单的一个插件：Voice Control for ChatGPT，可以在谷歌的插件商城进行下载，下载之后，在ChatGPT页面下面会出现这样一个麦，这样就可以进行口语的输入了。

  像这样的AI口语教育，国内已经有应用落地了，有一个**留学生的博主搞了一个小程序——AI口语练习室，就直接调用了该功能**，实现了AI口语教育的落地，你可能会说这**和直接抄有什么区别，不就是一个搬运**嘛，从本质上来说，他就是搬运的，**但是我们可以看到这里面大有可为，**并不是单纯的照搬，他们做了**功能的细化**，把英语分成两种应试和应用两种模块，应试模块里面有雅思、托福、BEC、口语模拟等功能，应用模块里面有旅游场景、面试场景、商务场景的英语练习，这里面就包含了各种以prompt为主的测试和产品设计，目前该小程序是采用会员制收费的。

# ChatGPT正式踏上商业变现之路：付费版价格敲定 每月20美元

　　**《科创板日报》2月2日讯（编辑 郑远方）**蹿红之后，ChatGPT正式踏上商业变现之路。

　　当地时间周三，**OpenAI推出ChatGPT付费订阅版ChatGPT Plus，每月收费20[美元](http://forex.jrj.com.cn/list/zt_my.shtml)（按照2月2日[汇率](http://summary.jrj.com.cn/forex/qbhl.shtml)计算，约合135元[人民币](http://forex.jrj.com.cn/list/rmbdt.shtml)）**。

　　购买后，VIP用户可在ChatGPT高峰时段继续使用，并提前获得ChatGPT的新功能与改进，服务响应时间也将有所缩短。

　　值得一提的是，**OpenAI曾在1月试行另一版收费项目ChatGPT Professional**，功能包括永远可用（没有停止服务时间）、快速回应（没有流量管制限制）、不限次数问答（每日数量是现在的至少2倍）。ChatGPT Professional等待名单中的部分被选中用户透露，**其收费为42美元/月**。不过，官方并未对这一价格作出回应。

　　而本次的ChatGPT Plus将在未来几周内，率先在美国国内推出，之后将拓展至其他国家。OpenAI表示，有兴趣的用户可先在等待名单上登记注册。

　　当然，OpenAI也在公告中重申并未忽略免费版公户。其表示，将继续提供ChatGPT免费版服务，而通过20美元/月的订阅收费项目，OpenAI也可“帮助尽可能多的人使用免费服务”。不过，《纽约时报》指出，**在高峰时段，免费版访问人数将受到限制**。

　　OpenAI计划根据用户反馈及需求，继续完善并扩大ChatGPT Plus服务。此外，*公司还在积极探索更低价格的付费服务计划、商业计划与数据包选项*。

　　据瑞银集团2月1日的一份报告，**1月ChatGPT的月活跃用户有望达到1亿，这距离它推出只有2个月时间，成为史上增长最快的消费者应用**。随着用户群的快速涌入，为ChatGPT带来流量话题度与“免费教练”的同时，也快速推高其运算费用。

　　作为AI聊天[机器人](http://stock.jrj.com.cn/share,300024.shtml)(15.20 -0.65%,[诊股](http://stock.jrj.com.cn/share,300024,zhengu.shtml))，ChatGPT的运行成本极为高昂。此前OpenAI总裁兼董事长Greg Brockman已公开发帖，就“如何通过ChatGPT获利”向用户征求建议。

　　而OpenAI首席执行官Sam Altman也曾透露，**ChatGPT平均每一次聊天成本为“个位数美分”。而由于运算总成本高得难以想象，商业化收费变得很重要**。

　　放眼整个AIGC产业，**付费订阅服务似乎是产品走向商业化的必由之路**。

　　以同样主打“AI生成文案”的AIGC独角兽Jasper为例，其可*自动生成Instagram标题，编写TikTok视频脚本、广告营销*文本等内容。**该公司在成立当年（2021年），营收就达到了4500万美元，并收获7万名用户，客户包括IBM、爱彼迎等**。

　　从官网可以看到，Jasper是以类SAAS服务形式进行收费，且收费模式并不仅限于一种，甚至没有固定价格。以Boss Mode为例，若*每月生成10万字，则花费大约在82美元，若字数改变，收费也将出现相应变化。*

![img](images/20ihbpBs2B.webp)

　　总体而言，随着自然语言技术（NLP）进一步降低AI的使用和触达门槛，以及伴随着AIGC 生成算法的优化与改进，[国信证券](http://stock.jrj.com.cn/share,002736.shtml)(9.23 -0.75%,[诊股](http://stock.jrj.com.cn/share,002736,zhengu.shtml))认为，AIGC的商业化落地速度和效果表现将超出预期，AI正以越来越显性的方式产生商业模式。

　　分析师进一步指出，**虽然AIGC使C端用户以较低的门槛使用AI生成内容，但就目前来看，to B仍然是AIGC核心商业模式**。对于B端客户来说，他们的需求和付费意愿较为稳定：因为AIGC可为B端带来效率提升和成本下降，且能够填补原本很难完成的需求鸿沟。而面向C端的AIGC，则以SaaS订阅为主，包括效率工具与创作工具。

# 工作被ChatGPT取代，他们改去遛狗和修空调

### 因为聊天机器人的**原理**是**预测句子中最可能出现的单词**，**因此它会产生平庸的内容。这给公司带来了艰难的抉择：：是要确保质量还是节约成本？**

6月3日消息，随着ChatGPT等聊天机器人在各行各业中得到越来越广泛的应用，许多职业正在面临被取代的风险。特别是那些从事策划营销和社交媒体内容创作的人。一些公司已经发现，即使文案质量略微下降，降低成本也是值得的。这些被取代的白领们不得不转而依靠替人遛狗、修理空调之类的零工来维持生计。

**以下是[翻译](https://news.163.com/news/search?keyword=翻译)内容**

当[人工智能](https://news.163.com/news/search?keyword=人工智能)聊天机器人ChatGPT于2022年11月面世时，25岁的文案写手奥利维亚·利普金（Olivia Lipkin）并没有太在意。然而，在她所在的科技初创公司的内部聊天群中，有关如何在工作中使用这种工具的文章开始流传。当时，利普金是公司唯一的写手。

接下来的几个月里，利普金的工作任务越来越少。经理们开始在聊天群里称呼她为“奥利维亚-ChatGPT”。今年4月，利普金在没有任何解释的情况下被解雇了。但她在经理发布的文章中找到了原因：**使用ChatGPT比付钱给写手更便宜**。

"每当人们提到ChatGPT，我就感到不安和焦虑，害怕它会取代我，"利普金说：“如今，我有了确凿的证据证明自己的担心并不是杞人忧天，我失去了工作，因为人工智能取代了我。”

很多经济学家都预测，像ChatGPT这样的人工智能技术可能会取代许多工作岗位，从而引起一场类似工业革命的大规模“劳动力重组”。

目前，聊天机器人等工具已经开始**取代**一些工人的工作岗位，尤其是那些从事**策划营销**和**社交媒体内容创作**的人，这些工具看起来能够创造出一些合理的替代方案。

**专家表示**，即使是最先进的人工智能技术也无法与人类的写作技能相媲美，因为它们**缺乏个性化**的风格，而且经常会给出**错误、荒唐或带有偏见的答案**。然而，对许多公司来说，**以文案质量略微下降为代价**，来换取成本降低是**值得**的。

“我们现在正处于危机之中，”加州大学洛杉矶分校数字劳动力副教授萨拉·罗伯茨（Sarah T. Roberts）说，“人工智能正在取代许多本应不受到自动化影响的工作。”

**为何ChatGPT会变得又快又好？**

人工智能在过去一年中的质量迅速提高，产生了可以流畅对话、写歌甚至编写计算机代码的聊天机器人。为了推广这项技术，许多硅谷公司正在将这些产品免费推向更多用户。

几十年来，人工智能和算法一直是职场不可或缺的一部分。消费品公司、杂货店和仓储物流公司一直在使用预测算法和人工智能驱动的视觉系统，帮助他们制定业务决策、自动化某些机械任务和管理库存。在20世纪的大部分时间里，机器人一直在工厂中占据主导地位，许多办公任务也被软件所取代。

但最近兴起的生成式人工智能可能会掀起一股颠覆性的新浪潮。它使用复杂的算法，接受来自互联网上数以亿计的**单词和图像训练，并可以生成文本、图像和音频**。专家表示，这项技术能够大量生成看起来像真人撰写的答案，这**使得高薪知识型工作者成为被取代的目标。**

宾夕法尼亚大学沃顿商学院副教授伊桑·莫里克（Ethan Mollick）表示：“在之前的每一次自动化威胁中，自动化多是将艰苦、肮脏、重复性的工作自动化。而这一次，自动化威胁直接瞄准了收入最高、最具创造性的工作。这些工作往往需要接受更多教育的人才承担。”

今年3月，美国投行高盛预测，全球18%的工作可能会被人工智能自动化，而**律师等白领面临的风险将比建筑或维修等行业的工人更大。这份报告还称：“那些主要从事户外工作或体力劳动的职业，目前人工智能还无法完全实现自动化。”**

美国政府也已经敲响了警钟，白宫在去年12月发布的一份报告中表示：“人工智能有可能自动化‘非常规’任务，从而使大量新的劳动力面临潜在的[失业](https://news.163.com/news/search?keyword=失业)威胁。”

**ChatGPT“幻觉”无法修复？**

但莫里克称，现在评估人工智能对劳动力的威胁还为时过早。他指出，**文案、翻译和转录以及律师助理**等工作面临的**风险尤其大**。因为这些工作的任务**很容易交给聊天机器人完成**。**高级法律分析、创造性写作或艺术创作等可能不那么容易被取代**，因为人类在这些领域的表现仍然优于人工智能。

莫里克还说：“我们**可以把人工智能看成高级实习生**。有些工作主要是为了让新人入门某个行业，做点有用的事，它也是通往下一级的跳板。现在，这些工作正在遭受人工智能的威胁。”

埃里克·费恩（Eric Fein）来自伊利诺伊州布鲁明代尔，经营自己的内容写作业务已有10年。**他的业务范围从150字的浴垫描述到特殊网站文案，每小时收费60美元**。他已经建立了稳定的业务，有10份合同需要履行，这占他年收入的一半，为妻儿提供了舒适的生活。

然而在今年3月份，费恩收到了最大客户发来的通知：**由于采用了ChatGPT，将不再需要他的服务。**费恩的其他九份合同也因同样的原因被接连取消，整个文案业务几乎一夜之间就消失了。

费恩说：“这让我感觉筋疲力尽。”他请求这些客户重新考虑上述决定，并警告ChatGPT可能无法像他那样提供拥有**创造力、技术精确度和原创性**的内容。费恩表示，**客户们理解这一点，但**他们告诉他，**使用ChatGPT比支付给他的报酬要少得多**。

令人欣慰的是，费恩随后被他的一个客户重新雇用，因为后者对ChatGPT的工作不满意。然而，这还不足以养活费恩及其家人，他们的积蓄仅够坚持六个多月的时间。

现在，费恩决定从事一项人工智能无法胜任的工作，他已经报名参加了暖通空调技术员的培训课程。明年，他计划接受培训，成为一名水管工。他说：“这类培训可以帮助防患于未然！”

**人工智能是否会摧毁人类？**

许多企业曾尝试用聊天机器人代替员工，但都遭遇了惨败。比如，科技新闻网站CNET使用**人工智能撰写文章，结果错误百出，编辑们花费更多时间来修正**。一位**律师**使用ChatGPT撰写法律简报，却引用了许多**虚构的案例**。

据报道，美国国家饮食失调协会解雇了帮助热线的员工，用聊天机器人代替他们。但**聊天机器人**提供的建议**缺乏同情心，甚至有害**，因此他们暂停了使用这项技术。

加州大学洛杉矶分校罗伯茨教授表示聊天机器人可能会造成**代价高昂的错误**，那些急于将ChatGPT引入运营的公司“玩过火了”。因为聊天机器人的**原理**是**预测句子中最可能出现的单词**，**因此它会产生平庸的内容。这给公司带来了艰难的抉择：：是要确保质量还是节约成本？**

“我们必须问自己：聊天机器人是否足够好？模仿是否够了？我们仅仅关心这些吗？”罗伯茨说。“我们要降低质量标准，为了什么？让公司所有者和股东分到更大的一块蛋糕吗？”

广告文案撰写人利普金发现自己被ChatGPT替代之后，正在重新考虑是否继续从事办公室工作。她最初进入内容营销领域，是为了在追求创意写作的同时还能维持生计。但她发现这份工作让她感到疲惫不堪，难以按照自己的意愿写作。现在，她开始替人遛狗了。

利普金说：“我要完全脱离职场休息一段时间。人们正在寻找最便宜的解决方案，但那不是真正的人，而是机器人。”（小小）

# 谁能做出中国版ChatGPT？怎么做？

作者：符尧

单位：University of Edinburgh & Allen Institute for AI

联系方式：yao.fu@ed.ac.uk



> 在 2022 年一整年，本文作者符尧追踪了从 GPT-3 到 GPT-3.5 的全部版本迭代（参见《ChatGPT 的各项超能力从哪儿来？万字拆解追溯技术路线图来了！》），亲眼看到它一步步地从弱到强不断演化。在过去的一个月，他又走访了国内各大高校、研究院、大厂、创业公司、风投，将一些新的想法浓缩在这篇文章里。



2022 年 12 月，ChatGPT 横空出世。OpenAI 用一个核弹级的成果改变了科学研究和工程应用的范式。在中国，ChatGPT 受到了广泛的关注与深刻的讨论。在过去的一个月里，我走访各大高校，研究院，大厂，创业公司，风投；从北京到上海到杭州到深圳，跟所有头部的玩家们全部聊了一遍。The Game of Scale 在中国已然拉开，风暴中心的玩家们，在已知国内技术和生态与世界前沿的巨大鸿沟下，如何做成这件事？谁能做成这件事？



> 秦失其鹿，天下共逐之。 ——— 《史记・淮阴侯列传》



**目录**




## 一、三种不同的答案

我每接触到一个创业公司，都会问同一个问题：“ChatGPT 在那里，你们想做什么？” 我大概能收到三种不同的答案。第一个答案很明确，要做中国的 ChatGPT。

### 1.1 做中国的 ChatGPT

因为它就在那里，所以想要复现，想要国产化。这是**很经典的产品导向中文互联网思维**。这种思路也是过去二十年，中文互联网常见的商业模式：首先硅谷做出来一个东西，然后我们把它抄过来。

但这里的问题是，首先，ChatGPT 可不像打车软件，复现难度完全不可同日而语。光从人的角度看，GPT 的产生，是这个世界上最顶尖的科学家和工程师们从 2015 年开始就不断研究的结果。OpenAI 的首席科学家， Ilya Sutskever[1]，**深刻地相信 AGI 一定能实现**。作为图灵奖得主 Geoffery Hinton 的大弟子，从 2007 年就开始研究深度学习。他的 citation 有 37 万，发过的文章精准踩中了过去十年 Deep Learning 的所有关键节点。即使是如此强大的团队，从 GPT 2 到 GPT 3.5 也花了四年的时间，它的科学与工程的难度可想而知。

同时，初代 ChatGPT，是 OpenAI 在 GPT 3.5 的基础模型上，**花了两星期**时间对着 dialog 做 finetuning 之后**随手扔出来**的 demo。这里真正强的并不是 ChatGPT 这一个产品，而是底下的 GPT 3.5 基础模型。这个模型还在不断地演化，GPT 3.5 系列在 2022 年更新了三个大版本[2]，每个大版本都显著强于前一个版本；同样地，ChatGPT 发布两个月一共更新了四个小版本[3]，每个小版本都在单个的维度上比前一个版本有着明显的改进。OpenAI 的所有模型都在持续不断的演化，随时间推移越来越强。

这也就意味着，如果只盯着当前 ChatGPT 这一个产品看，**无异于刻舟求剑**。当 ChatGPT 出现的时候，它对已有的语音助手们形成了降维打击；如果看不到基础模型的演化，即使花个一两年辛辛苦苦做出一个类似的东西，那时候 OpenAI 的基础模型也在继续变强，如果他们接着产品化，以新的更强的基础模型 finetune 到一个更强的产品，难道要再被降维打击一次吗？

刻舟求剑的做法是行不通的。

### 1.2 做中国的 OpenAI

第二种答案是，要做中国的 OpenAI。给出这个答案的玩家，跳出了经典中文互联网产品思维。他们不止看到单个产品，而且还看到了这个产品背后，基础模型不断演化的强大驱动力，来源于**尖端人才的密度**和**先进的组织架构。**



- **尖端人才的密度**：不是一个人集资源带队然后把任务按层级打包分配给底下的人，而是一群顶级的集 science 和 engineering 于一身的人们共同协作。
- **先进的组织架构**：Language 团队与 Alignment 的团队相互合作迭代，然后底下 scaling 团队和 data 团队帮忙提供基础设施，每个 team 都非常小，但目标明确路径清晰，高度集中资源，朝着 AGI 进发



所以，如果要做这件事情，不只要看到产品，还要看到它背后的人才团队和组织架构；按稀缺程度排名的话，**人 >> 卡 >> 钱**。

但这里的问题是，不同的土壤*对创新的鼓励程度是不一样*的。在 OpenAI 刚创立的 2015 年，它的投资者们都相信 AGI ，即使当时看不到什么盈利的点。现在 GPT 做出来了，国内的投资者们也都信了 AGI，但相信的点或许也不一样：***到底是信 AGI 能挣钱，还是信 AGI 能推动人类发展***？

更进一步地，即使 OpenAI 就产生在这里，明天就出现，但他们跟微软达成的 deal，能否跟国内的云计算厂商达成呢？大模型的训练和推理都需要极大的成本，需要一个云计算引擎作为支撑。微软可以倾尽所有，让整个 Azure 给 OpenAI 打下手[4]，这个**换到国内，阿里云有可能给一个创业公司打下手吗**？

组织架构很重要，只有尖端的人才和先进的组织架构才能推动智能的不断迭代与进化；但它同样需要跟所在的土壤做适配，寻找可以 flourish 的方法。

### 1.3 探索智能的极限

第三种答案是，要**探索智能的极限**。这是我听到的最好的答案。它远超刻舟求剑式的经典互联网产品思维，也看到了组织架构和尖端人才密度的重要性，并且更重要地是它看到了未来，看到了模型演化与产品迭代，思考着如何把最深刻，最困难的问题用最创新的方法来解决。

这就涉及到了思考大模型的极限思维。

## 二、极限思维

观察现在的 ChatGPT / GPT-3.5 ，它明显是一个中间状态，它还有很多显著可以加强，并且马上就能加强的点，包括：



- **更长的输入框**：开始的时候，GPT 3.5 的上下文最长到八千个 token；现在的 ChatGPT 上下文建模的长度似乎已经过万。并且这个长度明显可以接着增长，在融入 efficient attention[5] 和 recursive encoding[6] 的方法之后，context length 应该可以接着 scale 到十万，甚至百万的长度
- **更大的模型，更大的数据**：模型的大小还没有到极限，MoE 可以接着把模型 scale 到 T 的量级[7]；数据的大小还没有到极限，人类反馈的数据每天都在增长
- **多模态**：在增加了多模态数据（音频，图片），特别是视频数据之后，总体与训练数据的大小可以再增大两个量级，这个可以让已知的能力接着按 scaling law 线性增加，同时还有可能继续出现新的涌现能力。比如可能模型在看过各种几何形状的图片，以及看过代数题之后，或许会自动学会做解析几何。
- *专业化*：现有的模型在文科上大概相当于研究生水平，但在理科上相当于高中或大一大二的学生水平；已有的工作已经证明我们可以把模型的技能点从一个方向挪到另一个方向，这就意味着即使不做任何 scaling，我们依然可以在通过牺牲其他方面能力的情况下，把模型朝着目标方向推进。比如牺牲掉模型的理科能力，*把它的文科能力从研究生推到专家教授的水准。*



以上四点只是现阶段可以看到的，马上就可以加强但暂时还没有加强的点，随着时间的推移和模型的演化，会有更多可以被 scale 的维度进一步体现出来。这意味着我们需要有极限的思维，思考当我们把能够拉满的维度全部拉满的时候，模型会是什么样子。

### 2.1 能够拉满全部拉满

模型的输入框可以接着加长，模型的大小可以继续增大，模型的数据可以继续增多，多模态的数据可以融合，模型的专业化程度可以继续增高，所有这些维度可以继续往上拉，模型还没有到极限。极限是一个过程，在这个过程中模型的能力会怎样发展呢？



- **Log-linear 曲线**：一部分能力的增长会遵循 log-linear 的曲线[8]，比如说某项任务的 finetuning。随着 finetune 数据的指数增长，模型所对应的 finetune 的任务的能力会线性增长。这部分能力会可预测地变得更强
- **Phase change 曲线**：一部分能力会随着 scaling 继续涌现[9]，比如说上文中的模型做解析几何的例子。随着可以被拉满的维度被不断拉满，新的，难以预测的涌现能力会接着出现。
- **多项式曲线？**当模型强到一定程度，与人类 align 到一定程度之后，或许一些能力的线性增长，所需要的数据，会突破指数增长的封锁，而降低到多项式的量级。也就是说，当模型强到一定程度之后，它或许不需要指数级的数据，而是只需要多项式级的数据，就可以完成泛化。这可以从人类的专业学习中观察到：*当一个人还不是领域专家的时候，ta 需要指数级的数据来学习领域的知识；当一个人已经是领域专家的时候了，ta 只需要很少量级的数据就自己迸发出新的灵感和知识。*



所以，在极限思维下，把所有能拉满的维度全部拉满，模型注定会越来越强，出现越来越多的涌现能力。

### 2.2 反推中间过程

在思考清楚极限的过程之后，就可以从极限状态往后反推中间过程。比如说，如果我们希望增长输入框的大小：



- 如果希望把模型的输入框从**千**的量级增长到**万**的量级，可能只需要**增加显卡数量**，进行显存优化就能实现。
- 如果希望接着把输入框从**万**的量级增长到**十万**的量级，可能需要**linear attention**[10]
- 的方法，因为此时加显存应该也架不住 attention 运算量随输入框长度的二次增长。
- 如果希望接着把输入框从十万的量级增长到百万的量级，可能需要**recursive encoding**[11]的方法和增加**long-term memory**[12]的方法，因为此时 linear attention 可能也架不住显存的增长。



以这种方式，我们可以反推不同阶段的 scaling 需要怎样的技术。以上分析不止适用于输入框的长度，也适用于其他因素的 scaling 的过程。

这样的话，我们可以得到清晰的**从现阶段的技术到 scaling 的极限的每个中间阶段的技术路线图**。

### 2.3 按模型演化进程产品化

模型在不断演化，但产品化不需要等到最终那个模型完成 — 每当模型迭代出来一个大的版本，都可以产品化。以 OpenAI 的产品化过程为例：

- 2020 年，初代 GPT 3 训练完成，开放 OpenAI API[13]
- 2021 年，初代 Codex 训练完成，开放 *Github Copilot*[14]
- 2022 年，GPT-3.5 训练完成，以 dialog 数据 finetune 成 ChatGPT 然后发布

可以看到，在中间阶段的每一个重要版本，模型的能力都会增强，都存在产品化的机会。

更加重要的是，按照模型演化进程产品化，可以在产品化的阶段适配市场。学习 OpenAI 的组织架构来推进模型演化本身，但产品化可以按照本土市场的特征来。这种方式或许可以既学到 OpenAI 的先进经验，又避免水土不服的问题。

## 三、人工智能显著超过人类的点

到目前为止，我们讨论了要用模型演化的视角来分析模型，要用极限的思维讨论模型的演化历程。现阶段马上可以加强的点包括了输入框的长度，更大的模型和数据，多模态数据，和模型的专业化程度。现在让我们再把视野放得更长期些，思考在更大的时间和空间中，模型如何进一步地往极限推。我们讨论：

- **并行感知**：一个人类研究员一次顺序地读四五篇论文已经是极限，但模型输入框变长之后，可以在极短的时间内并行阅读一百篇论文。这意味着，模型对外部信息的感知能力远超人类一个数量级。
- **记忆遗传**：人类的演化过程中，子代只继承父代的基因，但不继承父代的记忆，这意味着每一次生殖都需要重启一次；在模型的演化过程中，子代可以继承父代的记忆，并且这个继承的程度可控：我们可以设置子代继承 100%，50%，20% 的记忆，或清空记忆，这意味着父代的经验和技能可以不断累积
- **加速时间**：人类相互交流的速率是受到人类说话的物理速度限制的，而模型相互交流的速率可以远快于人类，这意味着模型可以通过相互交流来解决人类数据随时间线性增长的问题；人类演化的过程受到物理时间的限制，模型的演化可以比人类的物理时间快上几个数量级，这意味着模型的进步速度可以远快于人类
- **无限生命**：一个人的生命有限，百年之后终归尘土，但模型的权重只要不丢失，就可以不断地演化



从这些角度来说，人工智能超过人类并不是一件难以想象的事情。这就引发了下一个问题：**如何驾驭远超人类的强人工智能？**

这个问题，是 Alignment 这项技术真正想要解决的问题。

## 四、Alignment 对齐

**当前阶段，模型的能力，除了 AlphaGo 在围棋上超过了最强人类之外，其他方面的 AI 并没有超过最强的人类（但 *ChatGPT 在文科上或许已经超过了 95% 的人类，且它还在继续增长*）**。在模型还没超过人类的时候，Alignment 的任务是让模型符合人类的价值观和期望；但当模型继续演化到超过人类之后，Alignment 的任务就变成了寻找驾驭远超人类的智能体的方法。

### 4.1 Alignment 作为驾驭远超人类的智能体的方法

一个显然的问题是，当 AI 超过人类之后，还可以通过人类反馈让 ta 更强 / 更受约束吗？是不是这个时候就已经管不了了？

不一定，*即使模型远超人类，我们依然有可能驾驭 ta*，这里的一个例子是**运动员和教练**之间的关系：金牌运动员在 ta 的方向上已经是最强的人类了，但这并不意味着教练就不能训练 ta。相反，即使教练不如运动员，ta 依然可以通过各种反馈机制让运动员变得更强且更有纪律。

类似地，人类和强人工智能的关系，在 AI 发展的中后期，可能会变成运动员和教练之间的关系。这个时候，人类需要的能力**并不是完成一个目标**，而是**设定一个好的目标**，然后衡量机器是否足够好地完成了这个目标，并给出改进意见。

这个方向的研究还非常初步，这个新学科的名字，叫 Scalable Oversight[15].

### 4.2 Alignment 与组织架构

在通往强人工智能的路上，不只是需要人类与 AI 对齐，人类与人类，也需要高度的对齐。从组织架构的角度，alignment 涉及到：



- **Pretraining 团队与 instruction tuning - alignment 团队之间的对齐**：这两者应该是一个相互迭代的过程，pretraining 团队不断地 scale 基础模型，alignment 团队为基础模型做 instruction tuning，同时用得到的结果反向指导 pretraning 团队的方向。
- **Pretraining / Alignment 团队与 Scaling / Data 团队的对齐**：scaling 负责为 pretraining /alignment 做好基础设施，data 做好高质量数据与人类反馈数据。
- **创业公司与 VC 的对齐**：AGI 是一个困难的事情，需要长期的投入，这需要各个方面的人都有足够的耐心和足够高的视野。烧一趟热钱后催产品化然后占满市场的逻辑在大模型时代应该已经不复存在了。大模型的游戏要求 ta 的玩家们有足够高的视野与格局，模型的演化会让有足够耐心的，踏实做事的人们在长期得到丰厚的回报，也会让只看短期刻舟求剑的人们一次又一次被降维打击。



## 五、结语

在 2017 年，我刚刚入行 NLP 的时候，花了很大的力气做可控生成这件事情。那个时候所谓的 text style transfer 最多就是把句子情感分类改一改，把 good 改成 bad 就算是完成了 transfer。*2018* 年我花了大量的时间研究如何让模型从句子结构的角度*修改句子的风格，一度误认为风格转换是几乎不可能完成的事情。而今 ChatGPT 做风格转换简直信手拈来*。那些曾经看似不可能完成的任务，曾经极其困难的事情，今天大语言模型非常轻松地就能完成。在 2022 年一整年，我追踪了从 GPT-3 到 GPT-3.5 的全部版本迭代[11]，亲眼看到它一步步地从弱到强不断演化。这个演化速度并没有变慢，反而正在加快。那些原先看来科幻的事情，现在已经成为现实。谁会知道未来会怎样呢？



> 彼黍离离，彼稷之苗。行迈靡靡，中心摇摇。
> 彼黍离离，彼稷之穗。行迈靡靡，中心如醉。
> ——— 《诗经・黍离》